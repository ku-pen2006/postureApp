import SwiftUI
import AVFoundation

struct ContentView: View {
    @StateObject private var history = PostureHistory()
    @StateObject private var cameraManager: CameraManager

    init() {
        let history = PostureHistory()
        _history = StateObject(wrappedValue: history)
        _cameraManager = StateObject(wrappedValue: CameraManager(history: history))
    }

    var body: some View {
        TabView {
            // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ 
            CameraPreview(session: cameraManager.session)
                .tabItem { Label("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ", systemImage: "camera") }

            // ã‚°ãƒ©ãƒ•
            GraphView(history: history)
                .tabItem { Label("ã‚°ãƒ©ãƒ•", systemImage: "chart.bar.fill") }

            // æŒ¯ã‚Šè¿”ã‚Š
            SummaryView(history: history)
                .tabItem { Label("æŒ¯ã‚Šè¿”ã‚Š", systemImage: "clock.fill") }
        }
    }
}

//import SwiftUI
//import AVFoundation
//import Vision
//import AppKit
//
//// MARK: - ã‚«ãƒ¡ãƒ©ç®¡ç†
//class CameraManager: NSObject, ObservableObject {
//    let session = AVCaptureSession()
//    private var shoulderAngles: [Double] = [] // è‚©è§’åº¦ã®å±¥æ­´
//
//    override init() {
//        super.init()
//        setupCamera()
//    }
//
//    private func setupCamera() {
//        session.beginConfiguration()
//
//        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera,
//                                                   for: .video,
//                                                   position: .unspecified), // .front ã‚ˆã‚Š .unspecified ã®æ–¹ãŒMacã§ã¯ç¢ºå®Ÿ
//              let input = try? AVCaptureDeviceInput(device: camera),
//              session.canAddInput(input) else {
//            print("âŒ ã‚«ãƒ¡ãƒ©ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—ã—ã¾ã—ãŸ")
//            return
//        }
//        session.addInput(input)
//
//        let output = AVCaptureVideoDataOutput()
//        output.setSampleBufferDelegate(self, queue: DispatchQueue(label: "camera.queue"))
//
//        guard session.canAddOutput(output) else {
//            print("âŒ ãƒ“ãƒ‡ã‚ªå‡ºåŠ›ã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ")
//            return
//        }
//        session.addOutput(output)
//
//        session.commitConfiguration()
//
//        DispatchQueue.global(qos: .userInitiated).async {
//            self.session.startRunning()
//        }
//    }
//}
//
//// MARK: - å§¿å‹¢åˆ¤å®šå‡¦ç†
//extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
//    func captureOutput(_ output: AVCaptureOutput,
//                       didOutput sampleBuffer: CMSampleBuffer,
//                       from connection: AVCaptureConnection) {
//
//        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
//
//        let faceRequest = VNDetectFaceLandmarksRequest()
//        let bodyRequest = VNDetectHumanBodyPoseRequest()
//
//        // ğŸ’¡ å‘ã(orientation)ã®æŒ‡å®šã‚’å‰Šé™¤
//        let handler = VNImageRequestHandler(cvPixelBuffer: pixelBuffer, options: [:])
//        
//        do {
//            try handler.perform([faceRequest, bodyRequest])
//        } catch {
//            print("âŒ Visionãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œã«å¤±æ•—: \(error)")
//            return
//        }
//
//        // --- é¡”åˆ¤å®š ---
//        // ğŸ’¡ as? ã§ã®ã‚­ãƒ£ã‚¹ãƒˆãŒä¸è¦ãªãŸã‚ä¿®æ­£
//        if let faces = faceRequest.results, let face = faces.first {
//            analyzeFace(face)
//        }
//
//        // --- è‚©åˆ¤å®š ---
//        // ğŸ’¡ as? ã§ã®ã‚­ãƒ£ã‚¹ãƒˆãŒä¸è¦ãªãŸã‚ä¿®æ­£
//        if let bodies = bodyRequest.results, let body = bodies.first {
//            analyzeShoulders(body)
//        }
//    }
//
//    private func analyzeFace(_ face: VNFaceObservation) {
//        if let roll = face.roll?.doubleValue {
//            // ãƒ©ã‚¸ã‚¢ãƒ³ã‹ã‚‰åº¦ã¸ã®å¤‰æ›ï¼ˆåˆ†ã‹ã‚Šã‚„ã™ã•ã®ãŸã‚ï¼‰
//            let rollAngle = roll * 180 / .pi
//            if abs(rollAngle) < 6.0 { // Â±6åº¦ä»¥å†…
//                print("ğŸ™‚ é¡”ã¯æ°´å¹³")
//            } else {
//                print("âš ï¸ é¡”ãŒå‚¾ã„ã¦ã„ã¾ã™ (roll=\(String(format: "%.1f", rollAngle))åº¦)")
//            }
//        }
//
//        // å‰å‚¾ãƒã‚§ãƒƒã‚¯ï¼ˆé¡”ã®å¤§ãã•ã§åˆ¤å®šï¼‰
//        let faceHeight = face.boundingBox.height
//        if faceHeight > 0.45 {
//            print("âš ï¸ å‰å‚¾ã—ã¦ã„ã¾ã™ï¼ˆç”»é¢ã«è¿‘ã™ãï¼‰")
//        }
//
//        // æ¨ªã‚ºãƒ¬ãƒã‚§ãƒƒã‚¯
//        let offset = abs(face.boundingBox.midX - 0.5)
//        if offset > 0.15 { // é–¾å€¤ã‚’å°‘ã—åºƒã’ã‚‹
//            print("âš ï¸ æ¨ªã«ã‚ºãƒ¬ã¦ã„ã¾ã™")
//        }
//    }
//
//    private func analyzeShoulders(_ body: VNHumanBodyPoseObservation) {
//        // ğŸ’¡ recognizedPointsã®æŒ‡å®šæ–¹æ³•ã‚’ä¿®æ­£
//        guard let points = try? body.recognizedPoints(.all),
//              let leftShoulder = points[.leftShoulder], leftShoulder.confidence > 0.3, // èªè­˜ä¿¡é ¼åº¦ã®é–¾å€¤ã‚’å°‘ã—ä¸‹ã’ã‚‹
//              let rightShoulder = points[.rightShoulder], rightShoulder.confidence > 0.3 else {
//            return
//        }
//
//        let dx = rightShoulder.location.x - leftShoulder.location.x
//        let dy = rightShoulder.location.y - leftShoulder.location.y
//        let angle = atan2(dy, dx)
//
//        // å¹³æ»‘åŒ–ï¼ˆç›´è¿‘10ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¹³å‡ï¼‰
//        shoulderAngles.append(angle)
//        if shoulderAngles.count > 10 {
//            shoulderAngles.removeFirst()
//        }
//        let avgAngle = shoulderAngles.reduce(0,+) / Double(shoulderAngles.count)
//        
//        // ãƒ©ã‚¸ã‚¢ãƒ³ã‹ã‚‰åº¦ã¸ã®å¤‰æ›
//        let avgAngleDegrees = avgAngle * 180 / .pi
//
//        if abs(avgAngleDegrees) < 5.0 { // Â±5åº¦ä»¥å†…
//            print("âœ… è‚©ã¯æ°´å¹³")
//        } else {
//            print("âš ï¸ è‚©ãŒå‚¾ã„ã¦ã„ã¾ã™ (avg=\(String(format: "%.1f", avgAngleDegrees))åº¦)")
//        }
//    }
//}
//
//// MARK: - SwiftUIãƒ“ãƒ¥ãƒ¼
//struct ContentView: View {
//    @StateObject private var cameraManager = CameraManager()
//
//    var body: some View {
//        CameraPreview(session: cameraManager.session)
//            .ignoresSafeArea()
//    }
//}
//
//// MARK: - ã‚«ãƒ¡ãƒ©ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
//struct CameraPreview: NSViewRepresentable {
//    let session: AVCaptureSession
//
//    func makeNSView(context: Context) -> NSView {
//        let view = NSView()
//        view.wantsLayer = true
//
//        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
//        previewLayer.videoGravity = .resizeAspectFill
//        
//        // ğŸ’¡ viewã®layerãŒç¢ºå®šã—ã¦ã‹ã‚‰frameã‚’è¨­å®š
//        view.layer = CALayer()
//        view.layer?.addSublayer(previewLayer)
//        
//        // ğŸ’¡ AutoresizingMaskã‚’è¨­å®šã—ã¦ãƒªã‚µã‚¤ã‚ºã«å¯¾å¿œ
//        previewLayer.autoresizingMask = [.layerWidthSizable, .layerHeightSizable]
//        previewLayer.frame = view.bounds
//
//        return view
//    }
//
//    func updateNSView(_ nsView: NSView, context: Context) {}
//}
